{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "16852646-6d81-42aa-b6f4-a9dfb10e6608",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## API helpers for MLOps operation\n",
    "\n",
    "This notebook contains function to simplify MLOps operation during the demo, such as creating the MLOPs job if it doesn't exists, or webhook helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e1694caa-f4c6-45d7-a15a-ce587a4e414d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.utils.rest_utils import http_request\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad54599e-9c67-4e8c-a839-68e5f8120479",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Helper to get the MLOps Databricks job or create it if it doesn't exists\n",
    "def find_job(name, offset = 0, limit = 25):\n",
    "    r = http_request(host_creds=host_creds, endpoint=\"/api/2.1/jobs/list\", method=\"GET\", params={\"limit\": limit, \"offset\": offset, \"name\": urllib.parse.quote_plus(name)}).json()\n",
    "    if 'jobs' in r:\n",
    "        for job in r['jobs']:\n",
    "            if job[\"settings\"][\"name\"] == name:\n",
    "                return job\n",
    "        if r['has_more']:\n",
    "            return find_job(name, offset+limit, limit)\n",
    "    return None\n",
    "\n",
    "def get_churn_staging_job_id():\n",
    "  job = find_job(\"demos_churn_model_staging_validation\")\n",
    "  if job is not None:\n",
    "    return job['job_id']\n",
    "  else:\n",
    "    #the job doesn't exist, we dynamically create it.\n",
    "    #Note: requires DBR 10 ML to use automl model\n",
    "    notebook_path = dbutils.entry_point.getDbutils().notebook().getContext().notebookPath().get()\n",
    "    base_path = '/'.join(notebook_path.split('/')[:-1])\n",
    "    cloud_name = get_cloud_name()\n",
    "    if cloud_name == \"aws\":\n",
    "      node_type = \"i3.xlarge\"\n",
    "    elif cloud_name == \"azure\":\n",
    "      node_type = \"Standard_DS3_v2\"\n",
    "    elif cloud_name == \"gcp\":\n",
    "      node_type = \"n1-standard-4\"\n",
    "    else:\n",
    "      raise Exception(f\"Cloud '{cloud_name}' isn't supported!\")\n",
    "    job_settings = {\n",
    "                  \"email_notifications\": {},\n",
    "                  \"name\": \"demos_churn_model_staging_validation\",\n",
    "                  \"max_concurrent_runs\": 1,\n",
    "                  \"tasks\": [\n",
    "                      {\n",
    "                          \"new_cluster\": {\n",
    "                              \"spark_version\": \"12.2.x-cpu-ml-scala2.12\",\n",
    "                              \"spark_conf\": {\n",
    "                                  \"spark.databricks.cluster.profile\": \"singleNode\",\n",
    "                                  \"spark.master\": \"local[*, 4]\"\n",
    "                              },\n",
    "                              \"num_workers\": 0,\n",
    "                              \"node_type_id\": node_type,\n",
    "                              \"driver_node_type_id\": node_type,\n",
    "                              \"custom_tags\": {\n",
    "                                  \"ResourceClass\": \"SingleNode\"\n",
    "                              },\n",
    "                              \"spark_env_vars\": {\n",
    "                                  \"PYSPARK_PYTHON\": \"/databricks/python3/bin/python3\"\n",
    "                              },\n",
    "                              \"enable_elastic_disk\": True\n",
    "                          },\n",
    "                          \"notebook_task\": {\n",
    "                              \"notebook_path\": f\"{base_path}/05_job_staging_validation\"\n",
    "                          },\n",
    "                          \"email_notifications\": {},\n",
    "                          \"task_key\": \"test-model\"\n",
    "                      }\n",
    "                  ]\n",
    "          }\n",
    "    print(\"Job doesn't exists, creating it...\")\n",
    "    r = http_request(host_creds=host_creds, endpoint=\"/api/2.1/jobs/create\", method=\"POST\", json=job_settings).json()\n",
    "    return r['job_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6567bce3-0d7b-4982-8d7a-8f9491c9da6c",
     "showTitle": true,
     "title": "Helpers to manage Model registry webhooks"
    }
   },
   "outputs": [],
   "source": [
    "# Manage webhooks\n",
    "try:\n",
    "  from databricks_registry_webhooks import RegistryWebhooksClient, JobSpec, HttpUrlSpec\n",
    "  def create_job_webhook(model_name, job_id):\n",
    "    return RegistryWebhooksClient().create_webhook(\n",
    "      model_name = model_name,\n",
    "      events = [\"TRANSITION_REQUEST_CREATED\"],\n",
    "      job_spec = JobSpec(job_id=job_id, access_token=token),\n",
    "      description = \"Trigger the ops_validation job when a model is requested to move to staging.\",\n",
    "      status = \"ACTIVE\")\n",
    "\n",
    "  def create_notification_webhook(model_name, slack_url):\n",
    "    from databricks_registry_webhooks import RegistryWebhooksClient, JobSpec, HttpUrlSpec\n",
    "    return RegistryWebhooksClient().create_webhook(\n",
    "      model_name = model_name,\n",
    "      events = [\"TRANSITION_REQUEST_CREATED\"],\n",
    "      description = \"Notify the MLOps team that a model is requested to move to staging.\",\n",
    "      status = \"ACTIVE\",\n",
    "      http_url_spec = HttpUrlSpec(url=slack_url))\n",
    "\n",
    "  # List\n",
    "  def list_webhooks(model_name):\n",
    "    from databricks_registry_webhooks import RegistryWebhooksClient\n",
    "    return RegistryWebhooksClient().list_webhooks(model_name = model_name)\n",
    "\n",
    "  # Delete\n",
    "  def delete_webhooks(webhook_id):\n",
    "    from databricks_registry_webhooks import RegistryWebhooksClient\n",
    "    return RegistryWebhooksClient().delete_webhook(id=webhook_id)\n",
    "\n",
    "except:\n",
    "  def raise_exception():\n",
    "    print(\"You need to install databricks-registry-webhooks library to easily perform this operation (you could also use the rest API directly).\")\n",
    "    print(\"Please run: %pip install databricks-registry-webhooks \")\n",
    "    raise RuntimeError(\"function not available without databricks-registry-webhooks.\")\n",
    "\n",
    "  def create_job_webhook(model_name, job_id):\n",
    "    raise_exception()\n",
    "  def create_notification_webhook(model_name, slack_url):\n",
    "    raise_exception()\n",
    "  def list_webhooks(model_name):\n",
    "    raise_exception()\n",
    "  def delete_webhooks(webhook_id):\n",
    "    raise_exception()\n",
    "    \n",
    "def reset_webhooks(model_name):\n",
    "  whs = list_webhooks(model_name)\n",
    "  for wh in whs:\n",
    "    delete_webhooks(wh.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6466b6ba-3df8-401f-975f-6a3a7599d8fc",
     "showTitle": true,
     "title": "Slack notification helper"
    }
   },
   "outputs": [],
   "source": [
    "# Slack Notifications\n",
    "#Webhooks can be used to send emails, Slack messages, and more.  In this case we #use Slack.  We also use `dbutils.secrets` to not expose any tokens, but the URL #looks more or less like this:\n",
    "#`https://hooks.slack.com/services/T00000000/B00000000/XXXXXXXXXXXXXXXXXXXXXXXX`\n",
    "#You can read more about Slack webhooks [here](https://api.slack.com/messaging/webhooks#create_a_webhook).\n",
    "import urllib \n",
    "import json \n",
    "import requests, json\n",
    "\n",
    "def send_notification(message):\n",
    "  try:\n",
    "    slack_webhook = dbutils.secrets.get(\"rk_webhooks\", \"slack\")\n",
    "    body = {'text': message}\n",
    "    response = requests.post(\n",
    "      slack_webhook, data=json.dumps(body),\n",
    "      headers={'Content-Type': 'application/json'})\n",
    "    if response.status_code != 200:\n",
    "      raise ValueError(\n",
    "          'Request to slack returned an error %s, the response is:\\n%s'\n",
    "          % (response.status_code, response.text)\n",
    "      )\n",
    "  except:\n",
    "    print(\"slack isn't properly setup in this workspace.\")\n",
    "    pass\n",
    "  displayHTML(f\"\"\"<div style=\"border-radius: 10px; background-color: #adeaff; padding: 10px; width: 400px; box-shadow: 2px 2px 2px #F7f7f7; margin-bottom: 3px\">\n",
    "        <div style=\"padding-bottom: 5px\"><img style=\"width:20px; margin-bottom: -3px\" src=\"https://github.com/QuentinAmbard/databricks-demo/raw/main/media/resources/images/bell.png\"/> <strong>Churn Model update</strong></div>\n",
    "        {message}\n",
    "        </div>\"\"\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4314c8e2-f9f0-4ce1-a7ff-4afb418b890b",
     "showTitle": true,
     "title": "Transition model stage & write model comment helper"
    }
   },
   "outputs": [],
   "source": [
    "client = mlflow.tracking.client.MlflowClient()\n",
    "\n",
    "host_creds = client._tracking_client.store.get_host_creds()\n",
    "host = host_creds.host\n",
    "token = host_creds.token\n",
    "\n",
    "def mlflow_call_endpoint(endpoint, method, body='{}'):\n",
    "  if method == 'GET':\n",
    "      response = http_request(\n",
    "          host_creds=host_creds, endpoint=\"/api/2.0/mlflow/{}\".format(endpoint), method=method, params=json.loads(body))\n",
    "  else:\n",
    "      response = http_request(\n",
    "          host_creds=host_creds, endpoint=\"/api/2.0/mlflow/{}\".format(endpoint), method=method, json=json.loads(body))\n",
    "  return response.json()\n",
    "\n",
    "\n",
    "# Request transition to staging\n",
    "def request_transition(model_name, version, stage):\n",
    "  \n",
    "  staging_request = {'name': model_name,\n",
    "                     'version': version,\n",
    "                     'stage': stage,\n",
    "                     'archive_existing_versions': 'true'}\n",
    "  response = mlflow_call_endpoint('transition-requests/create', 'POST', json.dumps(staging_request))\n",
    "  return(response)\n",
    "  \n",
    "  \n",
    "# Comment on model\n",
    "def model_comment(model_name, version, comment):\n",
    "  \n",
    "  comment_body = {'name': model_name,\n",
    "                  'version': version, \n",
    "                  'comment': comment}\n",
    "  response = mlflow_call_endpoint('comments/create', 'POST', json.dumps(comment_body))\n",
    "  return(response)\n",
    "\n",
    "# Accept or reject transition request\n",
    "def accept_transition(model_name, version, stage, comment):\n",
    "  approve_request_body = {'name': model_details.name,\n",
    "                          'version': model_details.version,\n",
    "                          'stage': stage,\n",
    "                          'archive_existing_versions': 'true',\n",
    "                          'comment': comment}\n",
    "  \n",
    "  mlflow_call_endpoint('transition-requests/approve', 'POST', json.dumps(approve_request_body))\n",
    "\n",
    "def reject_transition(model_name, version, stage, comment):\n",
    "  \n",
    "  reject_request_body = {'name': model_details.name, \n",
    "                         'version': model_details.version, \n",
    "                         'stage': stage, \n",
    "                         'comment': comment}\n",
    "  \n",
    "  mlflow_call_endpoint('transition-requests/reject', 'POST', json.dumps(reject_request_body))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ace670f0-7223-4f3d-9089-f9bcdbf412b4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# After receiving payload from webhooks, use MLflow client to retrieve model details and lineage\n",
    "def fetch_webhook_data(): \n",
    "  try:\n",
    "    registry_event = json.loads(dbutils.widgets.get('event_message'))\n",
    "    model_name = registry_event['model_name']\n",
    "    model_version = registry_event['version']\n",
    "    if 'to_stage' in registry_event and registry_event['to_stage'] != 'Staging':\n",
    "      dbutils.notebook.exit()\n",
    "  except:\n",
    "    #If it's not in a job but interactive demo, we get the last version from the registry\n",
    "    model_name = 'dbdemos_mlops_churn'\n",
    "    model_version = client.get_latest_versions(model_name, ['None'])[0].version\n",
    "  return(model_name, model_version)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "API_Helpers",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
