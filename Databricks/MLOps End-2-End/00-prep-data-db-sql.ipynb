{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9474897c-547d-4f69-ae83-27598bbeeb9c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Save the data for DBSQL dashboards\n",
    "\n",
    "This reuse the files from the lakehouse demo. Please see bundle for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42b98080-a1c6-4f6b-bf30-8b1e007c3bd1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.dropdown(\"reset_all_data\", \"false\", [\"true\", \"false\"], \"Reset all data\")\n",
    "reset_all_data = dbutils.widgets.get(\"reset_all_data\") == \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4fdf1e6-335a-426e-aab0-d3ea66266cff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number, sha1, col, initcap, to_timestamp\n",
    "\n",
    "folder = \"/demos/retail/churn\"\n",
    "catalog = \"hive_metastore\"\n",
    "\n",
    "if reset_all_data:\n",
    "  #data generation on another notebook to avoid installing libraries (takes a few seconds to setup pip env)\n",
    "  print(f\"Generating data under {folder} , please wait a few sec...\")\n",
    "  path = dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get()\n",
    "  root_folder = \"mlops-end2end\"\n",
    "  parent_count = path[path.rfind(root_folder):].count('/') - 1\n",
    "  prefix = \"./\" if parent_count == 0 else parent_count*\"../\"\n",
    "  prefix = f'{prefix}_resources/'\n",
    "  dbutils.notebook.run(prefix+\"02-create-churn-tables\", 600, {\"root_folder\": root_folder, \"catalog\": catalog, \"db\": \"dbdemos_c360\", \"reset_all_data\": reset_all_data, \"cloud_storage_path\": \"/demos/\"})\n",
    "else:\n",
    "  print(\"data already existing. Run with reset_all_data=true to force a data cleanup for your local demo.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "00-prep-data-db-sql",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
