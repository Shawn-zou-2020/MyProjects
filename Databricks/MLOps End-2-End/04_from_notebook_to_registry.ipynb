{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fbf0061e-f2b7-426e-a72e-cb75de7e5ba2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Managing the model lifecycle with Model Registry\n",
    "\n",
    "<img src=\"https://github.com/QuentinAmbard/databricks-demo/raw/main/product_demos/mlops-end2end-flow-4.png\" width=\"1200\">\n",
    "\n",
    "One of the primary challenges among data scientists and ML engineers is the absence of a central repository for models, their versions, and the means to manage them throughout their lifecycle.  \n",
    "\n",
    "[The MLflow Model Registry](https://docs.databricks.com/applications/mlflow/model-registry.html) addresses this challenge and enables members of the data team to:\n",
    "<br><br>\n",
    "* **Discover** registered models, current stage in model development, experiment runs, and associated code with a registered model\n",
    "* **Transition** models to different stages of their lifecycle\n",
    "* **Deploy** different versions of a registered model in different stages, offering MLOps engineers ability to deploy and conduct testing of different model versions\n",
    "* **Test** models in an automated fashion\n",
    "* **Document** models throughout their lifecycle\n",
    "* **Secure** access and permission for model registrations, transitions or modifications\n",
    "\n",
    "<!-- Collect usage data (view). Remove it to disable collection. View README for more details.  -->\n",
    "<img width=\"1px\" src=\"https://ppxrzfxige.execute-api.us-west-2.amazonaws.com/v1/analytics?category=data-science&org_id=1549883858499596&notebook=%2F04_from_notebook_to_registry&demo_name=mlops-end2end&event=VIEW&path=%2F_dbdemos%2Fdata-science%2Fmlops-end2end%2F04_from_notebook_to_registry&version=1\">\n",
    "<!-- [metadata={\"description\":\"MLOps end2end workflow: Move model to registry and request transition to STAGING.\",\n",
    " \"authors\":[\"quentin.ambard@databricks.com\"],\n",
    " \"db_resources\":{},\n",
    "  \"search_tags\":{\"vertical\": \"retail\", \"step\": \"Data Engineering\", \"components\": [\"mlflow\"]},\n",
    "                 \"canonicalUrl\": {\"AWS\": \"\", \"Azure\": \"\", \"GCP\": \"\"}}] -->\n",
    "                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa862b0f-9a4a-4336-b850-b29aa65cc25c",
     "showTitle": false,
     "title": null
    }
   },
   "source": [
    "### A cluster has been created for this demo\n",
    "To run this demo, just select the cluster `dbdemos-mlops-end2end-shawnzou2020` from the dropdown menu ([open cluster configuration](https://dbc-abdbb8e0-f50f.cloud.databricks.com/#setting/clusters/0410-014028-ndqe9et5/configuration)). <br />\n",
    "*Note: If the cluster was deleted after 30 days, you can re-create it with `dbdemos.create_cluster('mlops-end2end')` or re-install the demo: `dbdemos.install('mlops-end2end')`*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "10805c37-b22e-4704-b292-737f31346629",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### How to Use the Model Registry\n",
    "Typically, data scientists who use MLflow will conduct many experiments, each with a number of runs that track and log metrics and parameters. During the course of this development cycle, they will select the best run within an experiment and register its model with the registry.  Think of this as **committing** the model to the registry, much as you would commit code to a version control system.  \n",
    "\n",
    "The registry defines several model stages: `None`, `Staging`, `Production`, and `Archived`. Each stage has a unique meaning. For example, `Staging` is meant for model testing, while `Production` is for models that have completed the testing or review processes and have been deployed to applications. \n",
    "\n",
    "Users with appropriate permissions can transition models between stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "19553e08-d57f-42b0-861c-f04e37092a02",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE CATALOG `hive_metastore`\nusing cloud_storage_path /Users/quentin.ambard@databricks.com/demos/retail\nusing catalog.database `hive_metastore`.`retail_quentin_ambard`\n"
     ]
    }
   ],
   "source": [
    "%run ./_resources/00-setup $reset_all_data=false $catalog=\"hive_metastore\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9cd5c026-3fae-45cd-89e2-330d5eb2fd00",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Sending our model to the registry\n",
    "\n",
    "We'll programatically select the best model from our last Auto-ML run and deploy it in the registry. We can easily do that using MLFlow `search_runs` API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a2d9749d-9ff2-4772-8598-577ca32c5f05",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>status</th>\n",
       "      <th>artifact_uri</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>metrics.test_accuracy_score</th>\n",
       "      <th>metrics.training_recall_score</th>\n",
       "      <th>metrics.training_precision_score</th>\n",
       "      <th>metrics.val_score</th>\n",
       "      <th>metrics.val_true_positives</th>\n",
       "      <th>metrics.test_score</th>\n",
       "      <th>metrics.training_roc_auc</th>\n",
       "      <th>metrics.test_roc_auc</th>\n",
       "      <th>metrics.val_recall_score</th>\n",
       "      <th>metrics.training_true_negatives</th>\n",
       "      <th>metrics.val_true_negatives</th>\n",
       "      <th>metrics.val_example_count</th>\n",
       "      <th>metrics.val_precision_recall_auc</th>\n",
       "      <th>metrics.val_f1_score</th>\n",
       "      <th>metrics.test_false_negatives</th>\n",
       "      <th>metrics.test_example_count</th>\n",
       "      <th>metrics.training_false_positives</th>\n",
       "      <th>metrics.training_score</th>\n",
       "      <th>metrics.test_true_negatives</th>\n",
       "      <th>metrics.test_f1_score</th>\n",
       "      <th>metrics.test_log_loss</th>\n",
       "      <th>metrics.training_example_count</th>\n",
       "      <th>metrics.test_false_positives</th>\n",
       "      <th>metrics.training_f1_score</th>\n",
       "      <th>metrics.training_false_negatives</th>\n",
       "      <th>metrics.val_precision_score</th>\n",
       "      <th>metrics.training_log_loss</th>\n",
       "      <th>metrics.val_log_loss</th>\n",
       "      <th>metrics.test_true_positives</th>\n",
       "      <th>metrics.test_precision_score</th>\n",
       "      <th>metrics.val_false_negatives</th>\n",
       "      <th>metrics.training_true_positives</th>\n",
       "      <th>metrics.val_false_positives</th>\n",
       "      <th>metrics.training_precision_recall_auc</th>\n",
       "      <th>...</th>\n",
       "      <th>params.classifier__importance_type</th>\n",
       "      <th>params.classifier__subsample</th>\n",
       "      <th>params.preprocessor__boolean__imputers</th>\n",
       "      <th>params.classifier__lambda_l1</th>\n",
       "      <th>params.classifier__colsample_bytree</th>\n",
       "      <th>params.preprocessor__verbose_feature_names_out</th>\n",
       "      <th>params.preprocessor__numerical__standardizer__with_mean</th>\n",
       "      <th>params.preprocessor__numerical__memory</th>\n",
       "      <th>params.preprocessor__numerical__standardizer</th>\n",
       "      <th>params.preprocessor__boolean__cast_type__inverse_func</th>\n",
       "      <th>params.preprocessor__boolean__steps</th>\n",
       "      <th>params.column_selector__cols</th>\n",
       "      <th>params.preprocessor__numerical__imputers__sparse_threshold</th>\n",
       "      <th>params.classifier__subsample_for_bin</th>\n",
       "      <th>params.preprocessor__boolean__cast_type__validate</th>\n",
       "      <th>params.classifier__min_split_gain</th>\n",
       "      <th>params.preprocessor__numerical__converter__check_inverse</th>\n",
       "      <th>params.preprocessor__boolean__onehot__dtype</th>\n",
       "      <th>params.preprocessor__boolean__imputers__remainder</th>\n",
       "      <th>params.preprocessor__boolean__cast_type__accept_sparse</th>\n",
       "      <th>params.classifier__min_child_samples</th>\n",
       "      <th>params.preprocessor__transformer_weights</th>\n",
       "      <th>params.preprocessor__numerical__imputers</th>\n",
       "      <th>params.preprocessor__numerical__converter__inv_kw_args</th>\n",
       "      <th>params.classifier__class_weight</th>\n",
       "      <th>params.classifier__max_depth</th>\n",
       "      <th>params.preprocessor__numerical__imputers__impute_mean__missing_values</th>\n",
       "      <th>params.classifier__lambda_l2</th>\n",
       "      <th>params.preprocessor__numerical__imputers__n_jobs</th>\n",
       "      <th>params.preprocessor__boolean__cast_type__kw_args</th>\n",
       "      <th>tags.mlflow.user</th>\n",
       "      <th>tags.model_type</th>\n",
       "      <th>tags.mlflow.source.name</th>\n",
       "      <th>tags.mlflow.runName</th>\n",
       "      <th>tags.estimator_class</th>\n",
       "      <th>tags.mlflow.log-model.history</th>\n",
       "      <th>tags.mlflow.databricks.notebookID</th>\n",
       "      <th>tags.mlflow.source.type</th>\n",
       "      <th>tags.estimator_name</th>\n",
       "      <th>tags.mlflow.datasets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d0d33d85f56f4561a77baf8c4a678cff</td>\n",
       "      <td>402627122877070</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>dbfs:/databricks/mlflow-tracking/4026271228770...</td>\n",
       "      <td>2023-06-21 12:53:25.737000+00:00</td>\n",
       "      <td>2023-06-21 12:53:44.833000+00:00</td>\n",
       "      <td>0.810754</td>\n",
       "      <td>0.562677</td>\n",
       "      <td>0.672297</td>\n",
       "      <td>0.795948</td>\n",
       "      <td>215.0</td>\n",
       "      <td>0.810754</td>\n",
       "      <td>0.862129</td>\n",
       "      <td>0.851221</td>\n",
       "      <td>0.547074</td>\n",
       "      <td>2877.0</td>\n",
       "      <td>885.0</td>\n",
       "      <td>1382.0</td>\n",
       "      <td>0.674456</td>\n",
       "      <td>0.603933</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1432.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>0.821471</td>\n",
       "      <td>916.0</td>\n",
       "      <td>0.64389</td>\n",
       "      <td>0.424309</td>\n",
       "      <td>4229.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.612622</td>\n",
       "      <td>464.0</td>\n",
       "      <td>0.673981</td>\n",
       "      <td>0.387719</td>\n",
       "      <td>0.440234</td>\n",
       "      <td>245.0</td>\n",
       "      <td>0.708092</td>\n",
       "      <td>178.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.67725</td>\n",
       "      <td>...</td>\n",
       "      <td>split</td>\n",
       "      <td>0.6744020945600699</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough', tra...</td>\n",
       "      <td>6.454044807263527</td>\n",
       "      <td>0.4909947649465118</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>None</td>\n",
       "      <td>[('cast_type', FunctionTransformer(func=&lt;funct...</td>\n",
       "      <td>['online_security_no', 'online_backup_yes', 'p...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>200000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>False</td>\n",
       "      <td>232</td>\n",
       "      <td>None</td>\n",
       "      <td>ColumnTransformer(transformers=[('impute_mean'...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>nan</td>\n",
       "      <td>93.78090037129849</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>quentin.ambard@databricks.com</td>\n",
       "      <td>lightgbm_classifier</td>\n",
       "      <td>Notebook: LightGBMClassifier</td>\n",
       "      <td>receptive-sloth-463</td>\n",
       "      <td>sklearn.pipeline.Pipeline</td>\n",
       "      <td>[{\"artifact_path\":\"model\",\"saved_input_example...</td>\n",
       "      <td>402627122878611</td>\n",
       "      <td>NOTEBOOK</td>\n",
       "      <td>Pipeline</td>\n",
       "      <td>[{\"name\":\"c798edc4c97f380c61bdcea4defa51de\",\"h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 150 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>run_id</th>\n      <th>experiment_id</th>\n      <th>status</th>\n      <th>artifact_uri</th>\n      <th>start_time</th>\n      <th>end_time</th>\n      <th>metrics.test_accuracy_score</th>\n      <th>metrics.training_recall_score</th>\n      <th>metrics.training_precision_score</th>\n      <th>metrics.val_score</th>\n      <th>metrics.val_true_positives</th>\n      <th>metrics.test_score</th>\n      <th>metrics.training_roc_auc</th>\n      <th>metrics.test_roc_auc</th>\n      <th>metrics.val_recall_score</th>\n      <th>metrics.training_true_negatives</th>\n      <th>metrics.val_true_negatives</th>\n      <th>metrics.val_example_count</th>\n      <th>metrics.val_precision_recall_auc</th>\n      <th>metrics.val_f1_score</th>\n      <th>metrics.test_false_negatives</th>\n      <th>metrics.test_example_count</th>\n      <th>metrics.training_false_positives</th>\n      <th>metrics.training_score</th>\n      <th>metrics.test_true_negatives</th>\n      <th>metrics.test_f1_score</th>\n      <th>metrics.test_log_loss</th>\n      <th>metrics.training_example_count</th>\n      <th>metrics.test_false_positives</th>\n      <th>metrics.training_f1_score</th>\n      <th>metrics.training_false_negatives</th>\n      <th>metrics.val_precision_score</th>\n      <th>metrics.training_log_loss</th>\n      <th>metrics.val_log_loss</th>\n      <th>metrics.test_true_positives</th>\n      <th>metrics.test_precision_score</th>\n      <th>metrics.val_false_negatives</th>\n      <th>metrics.training_true_positives</th>\n      <th>metrics.val_false_positives</th>\n      <th>metrics.training_precision_recall_auc</th>\n      <th>...</th>\n      <th>params.classifier__importance_type</th>\n      <th>params.classifier__subsample</th>\n      <th>params.preprocessor__boolean__imputers</th>\n      <th>params.classifier__lambda_l1</th>\n      <th>params.classifier__colsample_bytree</th>\n      <th>params.preprocessor__verbose_feature_names_out</th>\n      <th>params.preprocessor__numerical__standardizer__with_mean</th>\n      <th>params.preprocessor__numerical__memory</th>\n      <th>params.preprocessor__numerical__standardizer</th>\n      <th>params.preprocessor__boolean__cast_type__inverse_func</th>\n      <th>params.preprocessor__boolean__steps</th>\n      <th>params.column_selector__cols</th>\n      <th>params.preprocessor__numerical__imputers__sparse_threshold</th>\n      <th>params.classifier__subsample_for_bin</th>\n      <th>params.preprocessor__boolean__cast_type__validate</th>\n      <th>params.classifier__min_split_gain</th>\n      <th>params.preprocessor__numerical__converter__check_inverse</th>\n      <th>params.preprocessor__boolean__onehot__dtype</th>\n      <th>params.preprocessor__boolean__imputers__remainder</th>\n      <th>params.preprocessor__boolean__cast_type__accept_sparse</th>\n      <th>params.classifier__min_child_samples</th>\n      <th>params.preprocessor__transformer_weights</th>\n      <th>params.preprocessor__numerical__imputers</th>\n      <th>params.preprocessor__numerical__converter__inv_kw_args</th>\n      <th>params.classifier__class_weight</th>\n      <th>params.classifier__max_depth</th>\n      <th>params.preprocessor__numerical__imputers__impute_mean__missing_values</th>\n      <th>params.classifier__lambda_l2</th>\n      <th>params.preprocessor__numerical__imputers__n_jobs</th>\n      <th>params.preprocessor__boolean__cast_type__kw_args</th>\n      <th>tags.mlflow.user</th>\n      <th>tags.model_type</th>\n      <th>tags.mlflow.source.name</th>\n      <th>tags.mlflow.runName</th>\n      <th>tags.estimator_class</th>\n      <th>tags.mlflow.log-model.history</th>\n      <th>tags.mlflow.databricks.notebookID</th>\n      <th>tags.mlflow.source.type</th>\n      <th>tags.estimator_name</th>\n      <th>tags.mlflow.datasets</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>d0d33d85f56f4561a77baf8c4a678cff</td>\n      <td>402627122877070</td>\n      <td>FINISHED</td>\n      <td>dbfs:/databricks/mlflow-tracking/4026271228770...</td>\n      <td>2023-06-21 12:53:25.737000+00:00</td>\n      <td>2023-06-21 12:53:44.833000+00:00</td>\n      <td>0.810754</td>\n      <td>0.562677</td>\n      <td>0.672297</td>\n      <td>0.795948</td>\n      <td>215.0</td>\n      <td>0.810754</td>\n      <td>0.862129</td>\n      <td>0.851221</td>\n      <td>0.547074</td>\n      <td>2877.0</td>\n      <td>885.0</td>\n      <td>1382.0</td>\n      <td>0.674456</td>\n      <td>0.603933</td>\n      <td>170.0</td>\n      <td>1432.0</td>\n      <td>291.0</td>\n      <td>0.821471</td>\n      <td>916.0</td>\n      <td>0.64389</td>\n      <td>0.424309</td>\n      <td>4229.0</td>\n      <td>101.0</td>\n      <td>0.612622</td>\n      <td>464.0</td>\n      <td>0.673981</td>\n      <td>0.387719</td>\n      <td>0.440234</td>\n      <td>245.0</td>\n      <td>0.708092</td>\n      <td>178.0</td>\n      <td>597.0</td>\n      <td>104.0</td>\n      <td>0.67725</td>\n      <td>...</td>\n      <td>split</td>\n      <td>0.6744020945600699</td>\n      <td>ColumnTransformer(remainder='passthrough', tra...</td>\n      <td>6.454044807263527</td>\n      <td>0.4909947649465118</td>\n      <td>True</td>\n      <td>True</td>\n      <td>None</td>\n      <td>StandardScaler()</td>\n      <td>None</td>\n      <td>[('cast_type', FunctionTransformer(func=&lt;funct...</td>\n      <td>['online_security_no', 'online_backup_yes', 'p...</td>\n      <td>0.3</td>\n      <td>200000</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>True</td>\n      <td>&lt;class 'numpy.float64'&gt;</td>\n      <td>passthrough</td>\n      <td>False</td>\n      <td>232</td>\n      <td>None</td>\n      <td>ColumnTransformer(transformers=[('impute_mean'...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>5</td>\n      <td>nan</td>\n      <td>93.78090037129849</td>\n      <td>None</td>\n      <td>None</td>\n      <td>quentin.ambard@databricks.com</td>\n      <td>lightgbm_classifier</td>\n      <td>Notebook: LightGBMClassifier</td>\n      <td>receptive-sloth-463</td>\n      <td>sklearn.pipeline.Pipeline</td>\n      <td>[{\"artifact_path\":\"model\",\"saved_input_example...</td>\n      <td>402627122878611</td>\n      <td>NOTEBOOK</td>\n      <td>Pipeline</td>\n      <td>[{\"name\":\"c798edc4c97f380c61bdcea4defa51de\",\"h...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 150 columns</p>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Let's get our last auto ml run. This is specific to the demo, it just gets the experiment ID of the last Auto ML run.\n",
    "experiment_id = get_automl_churn_run()['experiment_id']\n",
    "\n",
    "best_model = mlflow.search_runs(experiment_ids=[experiment_id], order_by=[\"metrics.val_f1_score DESC\"], max_results=1, filter_string=\"status = 'FINISHED'\")\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e97df952-79c7-4327-86ae-0ba02938f8a1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Once we have our best model, we can now deploy it in production using it's run ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23631a47-454b-4105-8bb5-d972e63e1890",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'dbdemos_mlops_churn' already exists. Creating a new version of this model...\n2023/06/21 12:58:02 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: dbdemos_mlops_churn, version 56\nCreated version '56' of model 'dbdemos_mlops_churn'.\n"
     ]
    }
   ],
   "source": [
    "run_id = best_model.iloc[0]['run_id']\n",
    "\n",
    "#add some tags that we'll reuse later to validate the model\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "client.set_tag(run_id, key='demographic_vars', value='seniorCitizen,gender_Female')\n",
    "client.set_tag(run_id, key='db_table', value=f'{dbName}.dbdemos_mlops_churn_features')\n",
    "\n",
    "#Deploy our autoML run in MLFlow registry\n",
    "model_details = mlflow.register_model(f\"runs:/{run_id}/model\", \"dbdemos_mlops_churn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a069c15-8149-4c4e-bcb5-7c3b30392734",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "At this point the model will be in `None` stage.  Let's update the description before moving it to `Staging`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6793240f-edee-4711-bca2-c717b5940c4c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Update Description\n",
    "We'll do this for the registered model overall, and the particular version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3e0a8d47-dfdd-49af-adf1-236e2117b92f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[23]: <ModelVersion: creation_timestamp=1687352282042, current_stage='None', description=('This model version was built using XGBoost. Eating too much cake is the sin '\n 'of gluttony. However, eating too much pie is okay because the sin of pie is '\n 'always zero.'), last_updated_timestamp=1687352288556, name='dbdemos_mlops_churn', run_id='d0d33d85f56f4561a77baf8c4a678cff', run_link='', source='dbfs:/databricks/mlflow-tracking/402627122877070/d0d33d85f56f4561a77baf8c4a678cff/artifacts/model', status='READY', status_message='', tags={}, user_id='7644138420879474', version='56'>"
     ]
    }
   ],
   "source": [
    "model_version_details = client.get_model_version(name=\"dbdemos_mlops_churn\", version=model_details.version)\n",
    "\n",
    "#The main model description, typically done once.\n",
    "client.update_registered_model(\n",
    "  name=model_details.name,\n",
    "  description=\"This model predicts whether a customer will churn.  It is used to update the Telco Churn Dashboard in DB SQL.\"\n",
    ")\n",
    "\n",
    "#Gives more details on this specific model version\n",
    "client.update_model_version(\n",
    "  name=model_details.name,\n",
    "  version=model_details.version,\n",
    "  description=\"This model version was built using XGBoost. Eating too much cake is the sin of gluttony. However, eating too much pie is okay because the sin of pie is always zero.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5aec9794-868e-411d-b61e-858bb0b2f696",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Request Transition to Staging\n",
    "\n",
    "<img style=\"float: right\" src=\"https://github.com/QuentinAmbard/databricks-demo/raw/main/retail/resources/images/churn_move_to_stating.gif\">\n",
    "\n",
    "Our model is now read! Let's request a transition to Staging. \n",
    "\n",
    "While this example is done using the API, we can also simply click on the Model Registry button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9b96498-8381-4282-b1f9-edd985507884",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[24]: {'request': {'creation_timestamp': 1687352288722,\n  'user_id': 'quentin.ambard@databricks.com',\n  'activity_type': 'REQUESTED_TRANSITION',\n  'comment': '',\n  'to_stage': 'Staging'}}"
     ]
    }
   ],
   "source": [
    "request_transition(model_name = \"dbdemos_mlops_churn\", version = model_details.version, stage = \"Staging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c592cc9-352c-4099-870f-cdd5ebcac222",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Leave Comment in Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13b2fc75-d912-45ff-89af-06a80ed99c69",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[25]: {'comment': {'creation_timestamp': 1687352288947,\n  'user_id': 'quentin.ambard@databricks.com',\n  'comment': 'This was the best model from AutoML, I think we can use it as a baseline.',\n  'last_updated_timestamp': 1687352288947,\n  'id': '56e2550e0ca246d5b5f222a7f187abef'}}"
     ]
    }
   ],
   "source": [
    "# Leave a comment for the ML engineer who will be reviewing the tests\n",
    "comment = \"This was the best model from AutoML, I think we can use it as a baseline.\"\n",
    "\n",
    "model_comment(model_name = \"dbdemos_mlops_churn\",\n",
    "             version = model_details.version,\n",
    "             comment = comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27cc261a-ee46-42ef-8fab-dd5ddf62125a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Next: MLOps model testing and validation\n",
    "\n",
    "Because we defined our webhooks earlier, a job will automatically start, testing the new model being deployed and validating the request.\n",
    "\n",
    "Remember our webhook setup ? That's the orange part in the diagram.\n",
    "\n",
    "<img style=\"float: right\" src=\"https://github.com/QuentinAmbard/databricks-demo/raw/main/retail/resources/images/churn-mlflow-webhook-1.png\" width=600 >\n",
    "\n",
    "If the model passes all the tests, it'll be accepted and moved into STAGING. Otherwise it'll be rejected, and a slack notification will be sent.\n",
    "\n",
    "Next: \n",
    " * Find out how the model is being tested befored moved to STAGING [using the Databricks Staging test notebook]($./05_job_staging_validation) (optional)\n",
    " * Or discover how to [run Batch and Real-time inference from our STAGING model]($./06_staging_inference)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "04_from_notebook_to_registry",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
